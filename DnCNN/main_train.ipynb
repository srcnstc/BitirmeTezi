{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"main_train.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMZJUe0f+2rwTO+8qZgnshY"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"is1AHqzvZqgG"},"source":["**Author : Sercan SATICI, Kasım 2020**"]},{"cell_type":"markdown","metadata":{"id":"DvMJ4Zc9fC3r"},"source":["**Kimlik Doğrulama**\n","Drive'ın kimlik doğrulaması gerçekleştirilir."]},{"cell_type":"code","metadata":{"id":"OryetTyDfFBo","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606471881681,"user_tz":-180,"elapsed":19579,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}},"outputId":"bc864e7b-4b9c-4346-8695-84e445e90acd"},"source":["!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n","!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n","!apt-get update -qq 2>&1 > /dev/null\n","!apt-get -y install -qq google-drive-ocamlfuse fuse\n","from google.colab import auth\n","auth.authenticate_user()\n","from oauth2client.client import GoogleCredentials\n","creds = GoogleCredentials.get_application_default()\n","import getpass\n","!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n","vcode = getpass.getpass()\n","!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"],"execution_count":37,"outputs":[{"output_type":"stream","text":["E: Package 'python-software-properties' has no installation candidate\n","··········\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"9bht63kxfF52"},"source":["**Mount işlemi**\n","Drive mount edilir."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aX3hMZe0fJ1c","executionInfo":{"status":"ok","timestamp":1606471886586,"user_tz":-180,"elapsed":918,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}},"outputId":"1d535332-ee08-405e-a1ac-6383b4925129"},"source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":38,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TIIgDbWsfOzV"},"source":["**Çalışma Ortamının Hazırlanması**\n","Çalışma dizinine set olunur."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5rh32cd6fVcR","executionInfo":{"status":"ok","timestamp":1606471889476,"user_tz":-180,"elapsed":1029,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}},"outputId":"450566bd-8ab8-4a0f-a2bd-2ad246b8e473"},"source":["import os\n","os.chdir(\"/content/drive/My Drive/BitirmeTezi/DnCNN\")\n","!ls"],"execution_count":39,"outputs":[{"output_type":"stream","text":["data\t\t   main_test.py      models\t  readme.png\n","data_generator.py  main_train.ipynb  __pycache__  results\n","main_test.ipynb    main_train.py     README.md\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Yzr0UzDWfkY9"},"source":["# **Train**"]},{"cell_type":"markdown","metadata":{"id":"3GZH7o0ybJmp"},"source":["**Kütüphanelerin Yüklenmesi**"]},{"cell_type":"code","metadata":{"id":"s4woEHO8fnGH","executionInfo":{"status":"ok","timestamp":1606471892830,"user_tz":-180,"elapsed":1027,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}}},"source":["import argparse\n","import re\n","import os, glob, datetime\n","import numpy as np\n","from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract\n","from keras.models import Model, load_model\n","from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n","from keras.optimizers import Adam\n","import data_generator as dg\n","import keras.backend as K"],"execution_count":40,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XmcedBFZbemC"},"source":["**Parametrelerin Ayarlanması**"]},{"cell_type":"code","metadata":{"id":"agiCBjYughRH","executionInfo":{"status":"ok","timestamp":1606471895880,"user_tz":-180,"elapsed":1054,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}}},"source":["## Params\n","parser = argparse.ArgumentParser()#parser namespace değişkeni oluşturulur.\n","parser.add_argument('--model', default='DnCNN', type=str, help='choose a type of model')\n","parser.add_argument('--batch_size', default=128, type=int, help='batch size')\n","parser.add_argument('--train_data', default='data/Train400', type=str, help='path of train data')\n","parser.add_argument('--sigma', default=25, type=int, help='noise level')\n","parser.add_argument('--epoch', default=2000, type=int, help='number of train epoches')\n","parser.add_argument('--lr', default=1e-3, type=float, help='initial learning rate for Adam')\n","parser.add_argument('--save_every', default=1, type=int, help='save model at every x epoches')\n","parser.add_argument('-f')#parse edebilmesi için, dummyParser argument eklenmiştir, SytemExit:2 hatasının önüne geçilmiştir.\n","args = parser.parse_args()"],"execution_count":41,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aX72-bXKcTMw"},"source":["**Kayıt Dizini Oluşturma**"]},{"cell_type":"code","metadata":{"id":"KNetUDAVg-ql","executionInfo":{"status":"ok","timestamp":1606471898418,"user_tz":-180,"elapsed":1035,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}}},"source":["save_dir = os.path.join('models',args.model+'_'+'sigma'+str(args.sigma)) \n","\n","if not os.path.exists(save_dir):\n","    os.mkdir(save_dir)"],"execution_count":42,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8214N8X1Xjr6"},"source":["**GPU Bilgisi**\n","Colab tarafından atanan GPU bilgisi görüntülenir. (Ücretsiz kullanım:Tesla K80, Ücretli kullanım:T4 veya P100)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ez1krHNwXmgc","executionInfo":{"status":"ok","timestamp":1606471900471,"user_tz":-180,"elapsed":955,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}},"outputId":"631dd7b1-0d18-4155-fd9c-166d996bbecd"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":43,"outputs":[{"output_type":"stream","text":["Fri Nov 27 10:11:41 2020       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 455.38       Driver Version: 418.67       CUDA Version: 10.1     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   36C    P0    41W / 300W |   3245MiB / 16130MiB |      0%      Default |\n","|                               |                      |                 ERR! |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"au6BnLjoXphQ"},"source":["**Bellek Bilgisi**\n","Kalan bellek bilgisi görüntülenir."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aJa4w25LXsbC","executionInfo":{"status":"ok","timestamp":1606471903417,"user_tz":-180,"elapsed":996,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}},"outputId":"c8ffa459-7e28-4240-d1ca-c20bc029f143"},"source":["from psutil import virtual_memory\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","  print('To enable a high-RAM runtime, select the Runtime > \"Change runtime type\"')\n","  print('menu, and then select High-RAM in the Runtime shape dropdown. Then, ')\n","  print('re-execute this cell.')\n","else:\n","  print('You are using a high-RAM runtime!')"],"execution_count":44,"outputs":[{"output_type":"stream","text":["Your runtime has 27.4 gigabytes of available RAM\n","\n","You are using a high-RAM runtime!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ONyJ-RUVcadF"},"source":["## **Fonksiyonlar**"]},{"cell_type":"markdown","metadata":{"id":"V49LHs5dc1-k"},"source":["**DnCNN**\n","Derinliği dışardan ayarlanabilir (default:17), katmanların Conv+ReLu, Conv+BN+ReLu şeklinde ilerlediği mimari oluşturulur."]},{"cell_type":"code","metadata":{"id":"UREnCtxVgsL3","executionInfo":{"status":"ok","timestamp":1606471906192,"user_tz":-180,"elapsed":1065,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}}},"source":["def DnCNN(depth,filters=64,image_channels=1, use_bnorm=True):\n","    layer_count = 0\n","    inpt = Input(shape=(None,None,image_channels),name = 'input'+str(layer_count))\n","    # 1st layer, Conv+relu\n","    layer_count += 1\n","    x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',name = 'conv'+str(layer_count))(inpt)\n","    layer_count += 1\n","    x = Activation('relu',name = 'relu'+str(layer_count))(x)\n","    # depth-2 layers, Conv+BN+relu\n","    for i in range(depth-2):\n","        layer_count += 1\n","        x = Conv2D(filters=filters, kernel_size=(3,3), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n","        if use_bnorm:\n","            layer_count += 1\n","            #x = BatchNormalization(axis=3, momentum=0.1,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n","            x = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n","        layer_count += 1\n","        x = Activation('relu',name = 'relu'+str(layer_count))(x)  \n","    # last layer, Conv\n","    layer_count += 1\n","    x = Conv2D(filters=image_channels, kernel_size=(3,3), strides=(1,1), kernel_initializer='Orthogonal',padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n","    layer_count += 1\n","    x = Subtract(name = 'subtract' + str(layer_count))([inpt, x])   # input - noise\n","    model = Model(inputs=inpt, outputs=x)\n","    \n","    return model  \n"],"execution_count":45,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FSH4LCtrdyBR"},"source":["**Son Kayıt Noktası**\n","Model eğitilirken \".hdf5\" uzantılı dosyaya kayıtlanır, dosyanın taranarak en son kaldığı noktayı, epoch başlangıcı olarak dönen fonksiyondur. "]},{"cell_type":"code","metadata":{"id":"5iDZAFsIc8pQ","executionInfo":{"status":"ok","timestamp":1606471909571,"user_tz":-180,"elapsed":1065,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}}},"source":["def findLastCheckpoint(save_dir):\n","    file_list = glob.glob(os.path.join(save_dir,'model_*.hdf5'))  # get name list of all .hdf5 files\n","    #file_list = os.listdir(save_dir)\n","    if file_list:\n","        epochs_exist = []\n","        for file_ in file_list:\n","            result = re.findall(\".*model_(.*).hdf5.*\",file_)\n","            #print(result[0])\n","            epochs_exist.append(int(result[0]))\n","        initial_epoch=max(epochs_exist)   \n","    else:\n","        initial_epoch = 0\n","    return initial_epoch  \n"],"execution_count":46,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BL5az_W5eG2V"},"source":["**Loglama**\n","Tarih/Saat bilgilerini ekrana print etmek için kullanılmaktadır."]},{"cell_type":"code","metadata":{"id":"IzlSNc0QdDfq","executionInfo":{"status":"ok","timestamp":1606471912258,"user_tz":-180,"elapsed":1083,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}}},"source":["def log(*args,**kwargs):\n","     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),*args,**kwargs)"],"execution_count":47,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"erTq3GPVeW0h"},"source":["**Learning rate** Adaptif olarak öğrenme hızı (learnin rate) \"lr\" ayarlanması yapılır. İlk 30 epoch için başlangıç 'lr' değeri kullanılırken, 30-60 epochlarında, 60-80 ve 80-epoch aralıklarında öğrenme hızı azaltılmaktadır."]},{"cell_type":"code","metadata":{"id":"OpUPC8QfdB_i","executionInfo":{"status":"ok","timestamp":1606471914255,"user_tz":-180,"elapsed":910,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}}},"source":["def lr_schedule(epoch):\n","    initial_lr = args.lr\n","    if epoch<=30:\n","        lr = initial_lr\n","    elif epoch<=60:\n","        lr = initial_lr/10\n","    elif epoch<=80:\n","        lr = initial_lr/20 \n","    else:\n","        lr = initial_lr/20 \n","    log('current learning rate is %2.8f' %lr)\n","    return lr"],"execution_count":48,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"f59s88bqe00S"},"source":["**Eğitim Veri Setinin Oluşturulması** 'datagenarator' kütüphanesi kullanılarak (data_genarator.py), veri arttırma (data augmentation) yapılır. \"sigma\" değerli AWGN gürültüsü imgeye eklenerek cleaned imge ve noisy imge döndürülür. "]},{"cell_type":"code","metadata":{"id":"eqwHpcVOc_-Y","executionInfo":{"status":"ok","timestamp":1606471916832,"user_tz":-180,"elapsed":878,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}}},"source":["def train_datagen(epoch_iter=2000,epoch_num=5,batch_size=128,data_dir=args.train_data):\n","    while(True):\n","        n_count = 0\n","        if n_count == 0:\n","            #print(n_count)\n","            xs = dg.datagenerator(data_dir)\n","            assert len(xs)%args.batch_size ==0, \\\n","            log('make sure the last iteration has a full batchsize, this is important if you use batch normalization!')\n","            xs = xs.astype('float32')/255.0\n","            indices = list(range(xs.shape[0]))\n","            n_count = 1\n","        for _ in range(epoch_num):\n","            np.random.shuffle(indices)    # shuffle\n","            for i in range(0, len(indices), batch_size):\n","                batch_x = xs[indices[i:i+batch_size]]\n","                noise =  np.random.normal(0, args.sigma/255.0, batch_x.shape)    # noise\n","                #noise =  K.random_normal(ge_batch_y.shape, mean=0, stddev=args.sigma/255.0)\n","                batch_y = batch_x + noise \n","                yield batch_y, batch_x"],"execution_count":49,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tcM7F-YtfyrC"},"source":["**Loss Fonksiyonu** MSE fonksiyonudur.\n","*Loss kaybını daha iyi anlamlandırabilmek adına ortalama yerine toplam (Sum of square error, SSE) ifade loglanmıştır.*"]},{"cell_type":"code","metadata":{"id":"r9nzf-kRc9dj","executionInfo":{"status":"ok","timestamp":1606471919844,"user_tz":-180,"elapsed":1074,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}}},"source":["# define loss\n","def sum_squared_error(y_true, y_pred):\n","    #return K.mean(K.square(y_pred - y_true), axis=-1)\n","    return K.sum(K.square(y_pred - y_true))/2"],"execution_count":50,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bIrwmhKAf81h"},"source":["# **Main**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aITYwSACixGr","executionInfo":{"status":"ok","timestamp":1606480940342,"user_tz":-180,"elapsed":9019186,"user":{"displayName":"Sercan SATICI","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhnLH1jn4KnphuotvGSqUC1L2HSp-F0MGgsT17E2Q=s64","userId":"14019873311707904269"}},"outputId":"8c1f89f8-b304-4d20-9725-dcdab60cfddd"},"source":["if __name__ == '__main__':\n","    # model selection\n","    model = DnCNN(depth=17,filters=64,image_channels=1,use_bnorm=True)#17 katmanlı DnCNN oluşturulur\n","    model.summary()#model özeti print edilir\n","    \n","    # load the last model in matconvnet style\n","    initial_epoch = findLastCheckpoint(save_dir=save_dir)#epoch başlangıç noktası \".hdf5\" uzantılı dosyadan alınır\n","    if initial_epoch > 0:  \n","        print('resuming by loading epoch %03d'%initial_epoch)\n","        model = load_model(os.path.join(save_dir,'model_%03d.hdf5'%initial_epoch), compile=False)#model yüklenir\n","    \n","    # compile the model\n","    model.compile(optimizer=Adam(0.001), loss=sum_squared_error)#model derlenir, 'Adam' optimizer learning rate:0.001 ile kullanılır\n","    \n","    # use call back functions\n","    checkpointer = ModelCheckpoint(os.path.join(save_dir,'model_{epoch:03d}.hdf5'), \n","                verbose=1, save_weights_only=False, period=args.save_every)#keras kütüphanesi \"ModelCheckpoint\" fonk. ile model kayıtlama\n","    csv_logger = CSVLogger(os.path.join(save_dir,'log.csv'), append=True, separator=',')#\".csv\" uzantılı dosyaya loglama yapılır\n","    lr_scheduler = LearningRateScheduler(lr_schedule)#adaptif olarak 'lr' ayarlanır\n","    \n","    history = model.fit_generator(train_datagen(batch_size=args.batch_size),\n","                steps_per_epoch=2000, epochs=args.epoch, verbose=1, initial_epoch=initial_epoch,\n","                callbacks=[checkpointer,csv_logger,lr_scheduler])#eğitim"],"execution_count":51,"outputs":[{"output_type":"stream","text":["Model: \"functional_5\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input0 (InputLayer)             [(None, None, None,  0                                            \n","__________________________________________________________________________________________________\n","conv1 (Conv2D)                  (None, None, None, 6 640         input0[0][0]                     \n","__________________________________________________________________________________________________\n","relu2 (Activation)              (None, None, None, 6 0           conv1[0][0]                      \n","__________________________________________________________________________________________________\n","conv3 (Conv2D)                  (None, None, None, 6 36864       relu2[0][0]                      \n","__________________________________________________________________________________________________\n","bn4 (BatchNormalization)        (None, None, None, 6 256         conv3[0][0]                      \n","__________________________________________________________________________________________________\n","relu5 (Activation)              (None, None, None, 6 0           bn4[0][0]                        \n","__________________________________________________________________________________________________\n","conv6 (Conv2D)                  (None, None, None, 6 36864       relu5[0][0]                      \n","__________________________________________________________________________________________________\n","bn7 (BatchNormalization)        (None, None, None, 6 256         conv6[0][0]                      \n","__________________________________________________________________________________________________\n","relu8 (Activation)              (None, None, None, 6 0           bn7[0][0]                        \n","__________________________________________________________________________________________________\n","conv9 (Conv2D)                  (None, None, None, 6 36864       relu8[0][0]                      \n","__________________________________________________________________________________________________\n","bn10 (BatchNormalization)       (None, None, None, 6 256         conv9[0][0]                      \n","__________________________________________________________________________________________________\n","relu11 (Activation)             (None, None, None, 6 0           bn10[0][0]                       \n","__________________________________________________________________________________________________\n","conv12 (Conv2D)                 (None, None, None, 6 36864       relu11[0][0]                     \n","__________________________________________________________________________________________________\n","bn13 (BatchNormalization)       (None, None, None, 6 256         conv12[0][0]                     \n","__________________________________________________________________________________________________\n","relu14 (Activation)             (None, None, None, 6 0           bn13[0][0]                       \n","__________________________________________________________________________________________________\n","conv15 (Conv2D)                 (None, None, None, 6 36864       relu14[0][0]                     \n","__________________________________________________________________________________________________\n","bn16 (BatchNormalization)       (None, None, None, 6 256         conv15[0][0]                     \n","__________________________________________________________________________________________________\n","relu17 (Activation)             (None, None, None, 6 0           bn16[0][0]                       \n","__________________________________________________________________________________________________\n","conv18 (Conv2D)                 (None, None, None, 6 36864       relu17[0][0]                     \n","__________________________________________________________________________________________________\n","bn19 (BatchNormalization)       (None, None, None, 6 256         conv18[0][0]                     \n","__________________________________________________________________________________________________\n","relu20 (Activation)             (None, None, None, 6 0           bn19[0][0]                       \n","__________________________________________________________________________________________________\n","conv21 (Conv2D)                 (None, None, None, 6 36864       relu20[0][0]                     \n","__________________________________________________________________________________________________\n","bn22 (BatchNormalization)       (None, None, None, 6 256         conv21[0][0]                     \n","__________________________________________________________________________________________________\n","relu23 (Activation)             (None, None, None, 6 0           bn22[0][0]                       \n","__________________________________________________________________________________________________\n","conv24 (Conv2D)                 (None, None, None, 6 36864       relu23[0][0]                     \n","__________________________________________________________________________________________________\n","bn25 (BatchNormalization)       (None, None, None, 6 256         conv24[0][0]                     \n","__________________________________________________________________________________________________\n","relu26 (Activation)             (None, None, None, 6 0           bn25[0][0]                       \n","__________________________________________________________________________________________________\n","conv27 (Conv2D)                 (None, None, None, 6 36864       relu26[0][0]                     \n","__________________________________________________________________________________________________\n","bn28 (BatchNormalization)       (None, None, None, 6 256         conv27[0][0]                     \n","__________________________________________________________________________________________________\n","relu29 (Activation)             (None, None, None, 6 0           bn28[0][0]                       \n","__________________________________________________________________________________________________\n","conv30 (Conv2D)                 (None, None, None, 6 36864       relu29[0][0]                     \n","__________________________________________________________________________________________________\n","bn31 (BatchNormalization)       (None, None, None, 6 256         conv30[0][0]                     \n","__________________________________________________________________________________________________\n","relu32 (Activation)             (None, None, None, 6 0           bn31[0][0]                       \n","__________________________________________________________________________________________________\n","conv33 (Conv2D)                 (None, None, None, 6 36864       relu32[0][0]                     \n","__________________________________________________________________________________________________\n","bn34 (BatchNormalization)       (None, None, None, 6 256         conv33[0][0]                     \n","__________________________________________________________________________________________________\n","relu35 (Activation)             (None, None, None, 6 0           bn34[0][0]                       \n","__________________________________________________________________________________________________\n","conv36 (Conv2D)                 (None, None, None, 6 36864       relu35[0][0]                     \n","__________________________________________________________________________________________________\n","bn37 (BatchNormalization)       (None, None, None, 6 256         conv36[0][0]                     \n","__________________________________________________________________________________________________\n","relu38 (Activation)             (None, None, None, 6 0           bn37[0][0]                       \n","__________________________________________________________________________________________________\n","conv39 (Conv2D)                 (None, None, None, 6 36864       relu38[0][0]                     \n","__________________________________________________________________________________________________\n","bn40 (BatchNormalization)       (None, None, None, 6 256         conv39[0][0]                     \n","__________________________________________________________________________________________________\n","relu41 (Activation)             (None, None, None, 6 0           bn40[0][0]                       \n","__________________________________________________________________________________________________\n","conv42 (Conv2D)                 (None, None, None, 6 36864       relu41[0][0]                     \n","__________________________________________________________________________________________________\n","bn43 (BatchNormalization)       (None, None, None, 6 256         conv42[0][0]                     \n","__________________________________________________________________________________________________\n","relu44 (Activation)             (None, None, None, 6 0           bn43[0][0]                       \n","__________________________________________________________________________________________________\n","conv45 (Conv2D)                 (None, None, None, 6 36864       relu44[0][0]                     \n","__________________________________________________________________________________________________\n","bn46 (BatchNormalization)       (None, None, None, 6 256         conv45[0][0]                     \n","__________________________________________________________________________________________________\n","relu47 (Activation)             (None, None, None, 6 0           bn46[0][0]                       \n","__________________________________________________________________________________________________\n","conv48 (Conv2D)                 (None, None, None, 1 576         relu47[0][0]                     \n","__________________________________________________________________________________________________\n","subtract49 (Subtract)           (None, None, None, 1 0           input0[0][0]                     \n","                                                                 conv48[0][0]                     \n","==================================================================================================\n","Total params: 558,016\n","Trainable params: 556,096\n","Non-trainable params: 1,920\n","__________________________________________________________________________________________________\n","resuming by loading epoch 1934\n","WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n","^_^-training data finished-^_^\n","2020-11-27 10:12:10: current learning rate is 0.00005000\n","Epoch 1935/2000\n","   2/2000 [..............................] - ETA: 1:10 - loss: 168.7155WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0097s vs `on_train_batch_end` time: 0.0617s). Check your callbacks.\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8441\n","Epoch 01935: saving model to models/DnCNN_sigma25/model_1935.hdf5\n","2000/2000 [==============================] - 135s 67ms/step - loss: 159.8441\n","2020-11-27 10:14:26: current learning rate is 0.00005000\n","Epoch 1936/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8643\n","Epoch 01936: saving model to models/DnCNN_sigma25/model_1936.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.8643\n","2020-11-27 10:16:41: current learning rate is 0.00005000\n","Epoch 1937/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9568\n","Epoch 01937: saving model to models/DnCNN_sigma25/model_1937.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.9568\n","2020-11-27 10:18:56: current learning rate is 0.00005000\n","Epoch 1938/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9678\n","Epoch 01938: saving model to models/DnCNN_sigma25/model_1938.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.9678\n","2020-11-27 10:21:12: current learning rate is 0.00005000\n","Epoch 1939/2000\n","1310/2000 [==================>...........] - ETA: 46s - loss: 159.9259^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7952\n","Epoch 01939: saving model to models/DnCNN_sigma25/model_1939.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 159.7952\n","2020-11-27 10:23:33: current learning rate is 0.00005000\n","Epoch 1940/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.1343\n","Epoch 01940: saving model to models/DnCNN_sigma25/model_1940.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 160.1343\n","2020-11-27 10:25:48: current learning rate is 0.00005000\n","Epoch 1941/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7824\n","Epoch 01941: saving model to models/DnCNN_sigma25/model_1941.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 159.7824\n","2020-11-27 10:28:04: current learning rate is 0.00005000\n","Epoch 1942/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0002\n","Epoch 01942: saving model to models/DnCNN_sigma25/model_1942.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 160.0002\n","2020-11-27 10:30:19: current learning rate is 0.00005000\n","Epoch 1943/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7859\n","Epoch 01943: saving model to models/DnCNN_sigma25/model_1943.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 159.7859\n","2020-11-27 10:32:35: current learning rate is 0.00005000\n","Epoch 1944/2000\n"," 620/2000 [========>.....................] - ETA: 1:33 - loss: 159.7629^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8559\n","Epoch 01944: saving model to models/DnCNN_sigma25/model_1944.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 159.8559\n","2020-11-27 10:34:56: current learning rate is 0.00005000\n","Epoch 1945/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9426\n","Epoch 01945: saving model to models/DnCNN_sigma25/model_1945.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 159.9426\n","2020-11-27 10:37:12: current learning rate is 0.00005000\n","Epoch 1946/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9343\n","Epoch 01946: saving model to models/DnCNN_sigma25/model_1946.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 159.9343\n","2020-11-27 10:39:28: current learning rate is 0.00005000\n","Epoch 1947/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9836\n","Epoch 01947: saving model to models/DnCNN_sigma25/model_1947.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 159.9836\n","2020-11-27 10:41:43: current learning rate is 0.00005000\n","Epoch 1948/2000\n","1930/2000 [===========================>..] - ETA: 4s - loss: 159.8524^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8508\n","Epoch 01948: saving model to models/DnCNN_sigma25/model_1948.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 159.8508\n","2020-11-27 10:44:05: current learning rate is 0.00005000\n","Epoch 1949/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.6810\n","Epoch 01949: saving model to models/DnCNN_sigma25/model_1949.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.6810\n","2020-11-27 10:46:20: current learning rate is 0.00005000\n","Epoch 1950/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0916\n","Epoch 01950: saving model to models/DnCNN_sigma25/model_1950.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 160.0916\n","2020-11-27 10:48:36: current learning rate is 0.00005000\n","Epoch 1951/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0548\n","Epoch 01951: saving model to models/DnCNN_sigma25/model_1951.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 160.0548\n","2020-11-27 10:50:51: current learning rate is 0.00005000\n","Epoch 1952/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.6829\n","Epoch 01952: saving model to models/DnCNN_sigma25/model_1952.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.6829\n","2020-11-27 10:53:06: current learning rate is 0.00005000\n","Epoch 1953/2000\n","1240/2000 [=================>............] - ETA: 51s - loss: 159.9671^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0235\n","Epoch 01953: saving model to models/DnCNN_sigma25/model_1953.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 160.0235\n","2020-11-27 10:55:28: current learning rate is 0.00005000\n","Epoch 1954/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8693\n","Epoch 01954: saving model to models/DnCNN_sigma25/model_1954.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.8693\n","2020-11-27 10:57:43: current learning rate is 0.00005000\n","Epoch 1955/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0363\n","Epoch 01955: saving model to models/DnCNN_sigma25/model_1955.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 160.0363\n","2020-11-27 10:59:58: current learning rate is 0.00005000\n","Epoch 1956/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7462\n","Epoch 01956: saving model to models/DnCNN_sigma25/model_1956.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.7462\n","2020-11-27 11:02:14: current learning rate is 0.00005000\n","Epoch 1957/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7972\n","Epoch 01957: saving model to models/DnCNN_sigma25/model_1957.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.7972\n","2020-11-27 11:04:29: current learning rate is 0.00005000\n","Epoch 1958/2000\n"," 550/2000 [=======>......................] - ETA: 1:37 - loss: 159.8554^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0040\n","Epoch 01958: saving model to models/DnCNN_sigma25/model_1958.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 160.0040\n","2020-11-27 11:06:50: current learning rate is 0.00005000\n","Epoch 1959/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7383\n","Epoch 01959: saving model to models/DnCNN_sigma25/model_1959.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.7383\n","2020-11-27 11:09:06: current learning rate is 0.00005000\n","Epoch 1960/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0404\n","Epoch 01960: saving model to models/DnCNN_sigma25/model_1960.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 160.0404\n","2020-11-27 11:11:21: current learning rate is 0.00005000\n","Epoch 1961/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7819\n","Epoch 01961: saving model to models/DnCNN_sigma25/model_1961.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.7819\n","2020-11-27 11:13:37: current learning rate is 0.00005000\n","Epoch 1962/2000\n","1860/2000 [==========================>...] - ETA: 9s - loss: 159.8720^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9186\n","Epoch 01962: saving model to models/DnCNN_sigma25/model_1962.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 159.9186\n","2020-11-27 11:15:58: current learning rate is 0.00005000\n","Epoch 1963/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7781\n","Epoch 01963: saving model to models/DnCNN_sigma25/model_1963.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 159.7781\n","2020-11-27 11:18:14: current learning rate is 0.00005000\n","Epoch 1964/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9024\n","Epoch 01964: saving model to models/DnCNN_sigma25/model_1964.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 159.9024\n","2020-11-27 11:20:30: current learning rate is 0.00005000\n","Epoch 1965/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0625\n","Epoch 01965: saving model to models/DnCNN_sigma25/model_1965.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 160.0625\n","2020-11-27 11:22:45: current learning rate is 0.00005000\n","Epoch 1966/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7736\n","Epoch 01966: saving model to models/DnCNN_sigma25/model_1966.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 159.7736\n","2020-11-27 11:25:01: current learning rate is 0.00005000\n","Epoch 1967/2000\n","1170/2000 [================>.............] - ETA: 56s - loss: 159.8564^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8960\n","Epoch 01967: saving model to models/DnCNN_sigma25/model_1967.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 159.8960\n","2020-11-27 11:27:22: current learning rate is 0.00005000\n","Epoch 1968/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0978\n","Epoch 01968: saving model to models/DnCNN_sigma25/model_1968.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 160.0978\n","2020-11-27 11:29:38: current learning rate is 0.00005000\n","Epoch 1969/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.4886\n","Epoch 01969: saving model to models/DnCNN_sigma25/model_1969.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.4886\n","2020-11-27 11:31:53: current learning rate is 0.00005000\n","Epoch 1970/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0930\n","Epoch 01970: saving model to models/DnCNN_sigma25/model_1970.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 160.0930\n","2020-11-27 11:34:09: current learning rate is 0.00005000\n","Epoch 1971/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8627\n","Epoch 01971: saving model to models/DnCNN_sigma25/model_1971.hdf5\n","2000/2000 [==============================] - 136s 68ms/step - loss: 159.8627\n","2020-11-27 11:36:24: current learning rate is 0.00005000\n","Epoch 1972/2000\n"," 480/2000 [======>.......................] - ETA: 1:42 - loss: 159.7998^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0538\n","Epoch 01972: saving model to models/DnCNN_sigma25/model_1972.hdf5\n","2000/2000 [==============================] - 141s 70ms/step - loss: 160.0538\n","2020-11-27 11:38:45: current learning rate is 0.00005000\n","Epoch 1973/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9227\n","Epoch 01973: saving model to models/DnCNN_sigma25/model_1973.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.9227\n","2020-11-27 11:41:00: current learning rate is 0.00005000\n","Epoch 1974/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7789\n","Epoch 01974: saving model to models/DnCNN_sigma25/model_1974.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.7789\n","2020-11-27 11:43:16: current learning rate is 0.00005000\n","Epoch 1975/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0050\n","Epoch 01975: saving model to models/DnCNN_sigma25/model_1975.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 160.0050\n","2020-11-27 11:45:31: current learning rate is 0.00005000\n","Epoch 1976/2000\n","1790/2000 [=========================>....] - ETA: 14s - loss: 159.7957^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9655\n","Epoch 01976: saving model to models/DnCNN_sigma25/model_1976.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 159.9655\n","2020-11-27 11:47:52: current learning rate is 0.00005000\n","Epoch 1977/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7698\n","Epoch 01977: saving model to models/DnCNN_sigma25/model_1977.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.7698\n","2020-11-27 11:50:07: current learning rate is 0.00005000\n","Epoch 1978/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9510\n","Epoch 01978: saving model to models/DnCNN_sigma25/model_1978.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.9510\n","2020-11-27 11:52:23: current learning rate is 0.00005000\n","Epoch 1979/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9652\n","Epoch 01979: saving model to models/DnCNN_sigma25/model_1979.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.9652\n","2020-11-27 11:54:38: current learning rate is 0.00005000\n","Epoch 1980/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7270\n","Epoch 01980: saving model to models/DnCNN_sigma25/model_1980.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.7270\n","2020-11-27 11:56:53: current learning rate is 0.00005000\n","Epoch 1981/2000\n","1100/2000 [===============>..............] - ETA: 1:00 - loss: 159.8977^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7549\n","Epoch 01981: saving model to models/DnCNN_sigma25/model_1981.hdf5\n","2000/2000 [==============================] - 141s 70ms/step - loss: 159.7549\n","2020-11-27 11:59:14: current learning rate is 0.00005000\n","Epoch 1982/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0408\n","Epoch 01982: saving model to models/DnCNN_sigma25/model_1982.hdf5\n","2000/2000 [==============================] - 135s 67ms/step - loss: 160.0408\n","2020-11-27 12:01:29: current learning rate is 0.00005000\n","Epoch 1983/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9539\n","Epoch 01983: saving model to models/DnCNN_sigma25/model_1983.hdf5\n","2000/2000 [==============================] - 135s 67ms/step - loss: 159.9539\n","2020-11-27 12:03:44: current learning rate is 0.00005000\n","Epoch 1984/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7569\n","Epoch 01984: saving model to models/DnCNN_sigma25/model_1984.hdf5\n","2000/2000 [==============================] - 135s 67ms/step - loss: 159.7569\n","2020-11-27 12:05:59: current learning rate is 0.00005000\n","Epoch 1985/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0777\n","Epoch 01985: saving model to models/DnCNN_sigma25/model_1985.hdf5\n","2000/2000 [==============================] - 134s 67ms/step - loss: 160.0777\n","2020-11-27 12:08:13: current learning rate is 0.00005000\n","Epoch 1986/2000\n"," 410/2000 [=====>........................] - ETA: 1:46 - loss: 159.0293^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9127\n","Epoch 01986: saving model to models/DnCNN_sigma25/model_1986.hdf5\n","2000/2000 [==============================] - 140s 70ms/step - loss: 159.9127\n","2020-11-27 12:10:33: current learning rate is 0.00005000\n","Epoch 1987/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7183\n","Epoch 01987: saving model to models/DnCNN_sigma25/model_1987.hdf5\n","2000/2000 [==============================] - 135s 67ms/step - loss: 159.7183\n","2020-11-27 12:12:48: current learning rate is 0.00005000\n","Epoch 1988/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8699\n","Epoch 01988: saving model to models/DnCNN_sigma25/model_1988.hdf5\n","2000/2000 [==============================] - 134s 67ms/step - loss: 159.8699\n","2020-11-27 12:15:03: current learning rate is 0.00005000\n","Epoch 1989/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9536\n","Epoch 01989: saving model to models/DnCNN_sigma25/model_1989.hdf5\n","2000/2000 [==============================] - 135s 67ms/step - loss: 159.9536\n","2020-11-27 12:17:17: current learning rate is 0.00005000\n","Epoch 1990/2000\n","1720/2000 [========================>.....] - ETA: 18s - loss: 159.8682^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8298\n","Epoch 01990: saving model to models/DnCNN_sigma25/model_1990.hdf5\n","2000/2000 [==============================] - 140s 70ms/step - loss: 159.8298\n","2020-11-27 12:19:37: current learning rate is 0.00005000\n","Epoch 1991/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0468\n","Epoch 01991: saving model to models/DnCNN_sigma25/model_1991.hdf5\n","2000/2000 [==============================] - 135s 67ms/step - loss: 160.0468\n","2020-11-27 12:21:52: current learning rate is 0.00005000\n","Epoch 1992/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.6376\n","Epoch 01992: saving model to models/DnCNN_sigma25/model_1992.hdf5\n","2000/2000 [==============================] - 135s 67ms/step - loss: 159.6376\n","2020-11-27 12:24:07: current learning rate is 0.00005000\n","Epoch 1993/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8527\n","Epoch 01993: saving model to models/DnCNN_sigma25/model_1993.hdf5\n","2000/2000 [==============================] - 135s 67ms/step - loss: 159.8527\n","2020-11-27 12:26:22: current learning rate is 0.00005000\n","Epoch 1994/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 160.1879\n","Epoch 01994: saving model to models/DnCNN_sigma25/model_1994.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 160.1879\n","2020-11-27 12:28:37: current learning rate is 0.00005000\n","Epoch 1995/2000\n","1030/2000 [==============>...............] - ETA: 1:05 - loss: 159.6819^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 160.0307\n","Epoch 01995: saving model to models/DnCNN_sigma25/model_1995.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 160.0307\n","2020-11-27 12:30:58: current learning rate is 0.00005000\n","Epoch 1996/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7839\n","Epoch 01996: saving model to models/DnCNN_sigma25/model_1996.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.7839\n","2020-11-27 12:33:14: current learning rate is 0.00005000\n","Epoch 1997/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.7237\n","Epoch 01997: saving model to models/DnCNN_sigma25/model_1997.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.7237\n","2020-11-27 12:35:29: current learning rate is 0.00005000\n","Epoch 1998/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.9163\n","Epoch 01998: saving model to models/DnCNN_sigma25/model_1998.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.9163\n","2020-11-27 12:37:44: current learning rate is 0.00005000\n","Epoch 1999/2000\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8784\n","Epoch 01999: saving model to models/DnCNN_sigma25/model_1999.hdf5\n","2000/2000 [==============================] - 135s 68ms/step - loss: 159.8784\n","2020-11-27 12:40:00: current learning rate is 0.00005000\n","Epoch 2000/2000\n"," 340/2000 [====>.........................] - ETA: 1:51 - loss: 159.9151^_^-training data finished-^_^\n","2000/2000 [==============================] - ETA: 0s - loss: 159.8561\n","Epoch 02000: saving model to models/DnCNN_sigma25/model_2000.hdf5\n","2000/2000 [==============================] - 141s 71ms/step - loss: 159.8561\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zTWsi0HNQrAL"},"source":[""],"execution_count":null,"outputs":[]}]}